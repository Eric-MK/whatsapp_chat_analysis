{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas for data manipulation and analysis\n",
    "import pandas as pd\n",
    "\n",
    "# Import regular expressions for string manipulation\n",
    "import re\n",
    "\n",
    "# Import Counter from collections for counting occurrences\n",
    "from collections import Counter\n",
    "\n",
    "# Import matplotlib.pyplot for data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import seaborn for advanced statistical data visualization\n",
    "import seaborn as sns\n",
    "\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the chat file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              DateTime               Author  \\\n",
      "0  2020-11-18 21:47:16   RMS DIGITAL REVAMP   \n",
      "1  2020-11-18 21:47:16        Carol Wanyama   \n",
      "2  2022-10-19 14:00:38   RMS DIGITAL REVAMP   \n",
      "3  2022-10-19 14:04:16        Carol Wanyama   \n",
      "4  2022-10-19 14:04:26        Carol Wanyama   \n",
      "5  2022-10-19 14:05:24       Wachira Waruru   \n",
      "6  2022-10-19 14:07:39        Carol Wanyama   \n",
      "7  2022-10-19 14:08:30  Crispin Royal Media   \n",
      "8  2022-10-19 14:08:44        Carol Wanyama   \n",
      "9  2022-10-19 14:10:28       Wachira Waruru   \n",
      "10 2022-10-19 14:10:37        Wahiga Mwaura   \n",
      "11 2022-10-19 14:11:23        Carol Wanyama   \n",
      "12 2022-10-19 14:16:08          Ephy Mwangi   \n",
      "13 2022-10-19 14:17:31     Alex Murungi Rms   \n",
      "14 2022-10-19 14:18:24       Wachira Waruru   \n",
      "15 2022-10-19 14:18:31       Wachira Waruru   \n",
      "16 2022-10-19 14:18:51        Carol Wanyama   \n",
      "17 2022-10-19 14:19:51               Latifa   \n",
      "18 2022-10-19 14:22:57  Crispin Royal Media   \n",
      "19 2022-10-19 14:23:44          Ephy Mwangi   \n",
      "20 2022-10-19 14:25:51        Carol Wanyama   \n",
      "21 2022-10-19 14:29:48        Carol Wanyama   \n",
      "22 2022-10-19 14:31:17   Philip Mwaniki Rms   \n",
      "23 2022-10-19 14:31:47   Philip Mwaniki Rms   \n",
      "24 2022-10-19 14:31:57        Carol Wanyama   \n",
      "25 2022-10-19 14:42:14               Latifa   \n",
      "26 2022-10-19 14:43:45        Carol Wanyama   \n",
      "27 2022-10-19 14:48:50  Crispin Royal Media   \n",
      "28 2022-10-19 15:29:40        Carol Wanyama   \n",
      "29 2022-10-19 15:29:41        Carol Wanyama   \n",
      "30 2022-10-19 15:41:06        Wahiga Mwaura   \n",
      "31 2022-10-19 18:58:03        Wahiga Mwaura   \n",
      "32 2022-10-19 21:24:34      James Bundi Rms   \n",
      "33 2022-10-20 00:05:36  Crispin Royal Media   \n",
      "34 2022-10-20 00:08:23        Wahiga Mwaura   \n",
      "35 2022-10-20 07:21:32  Crispin Royal Media   \n",
      "36 2022-10-20 07:34:38        Wahiga Mwaura   \n",
      "37 2022-10-20 08:07:27  Crispin Royal Media   \n",
      "38 2022-10-20 08:17:15        Carol Wanyama   \n",
      "39 2022-10-20 08:38:42          Ephy Mwangi   \n",
      "40 2022-10-20 08:55:08        Wahiga Mwaura   \n",
      "41 2022-10-20 09:40:37           Afune Fred   \n",
      "42 2022-10-20 11:40:30       Wachira Waruru   \n",
      "43 2022-10-20 11:40:51        Wahiga Mwaura   \n",
      "44 2022-10-20 12:07:15      James Bundi Rms   \n",
      "45 2022-10-20 12:28:04           Afune Fred   \n",
      "46 2022-10-20 12:39:54      James Bundi Rms   \n",
      "47 2022-10-20 12:57:06      James Bundi Rms   \n",
      "48 2022-10-20 13:00:11      James Bundi Rms   \n",
      "49 2022-10-20 13:01:16       Wachira Waruru   \n",
      "\n",
      "                                              Message  \n",
      "0   Messages and calls are end-to-end encrypted. N...  \n",
      "1                    Carol Wanyama created this group  \n",
      "2                             Carol Wanyama added you  \n",
      "3                                       image omitted  \n",
      "4                            Birthday Cake LoadingðŸ¥³ðŸ¥³ðŸ¥³  \n",
      "5             Looks great,  when will it be consumed?  \n",
      "6                        This afternoon, very shortly  \n",
      "7              wow, looks amazing. Happy 1st birthday  \n",
      "8   We're sharing smaller versions with your vario...  \n",
      "9   Any chance that a small piece can be conveyed ...  \n",
      "10                                                ðŸ˜…ðŸ˜…ðŸ˜…  \n",
      "11                                  But ofcourse ðŸ˜…ðŸ˜…ðŸ˜…ðŸ˜…  \n",
      "12                                    sticker omitted  \n",
      "13                                    sticker omitted  \n",
      "14                                    sticker omitted  \n",
      "15                                     Even me I have  \n",
      "16                                             ðŸ˜‚ðŸ˜‚ðŸ˜‚ðŸ˜‚ðŸ˜‚ðŸ˜‚  \n",
      "17                                           Awesome!  \n",
      "18                                           hahahaha  \n",
      "19                                    sticker omitted  \n",
      "20                                                ðŸ˜‚ðŸ˜‚ðŸ˜‚  \n",
      "21                                    sticker omitted  \n",
      "22                                    sticker omitted  \n",
      "23                                    sticker omitted  \n",
      "24                                                 ðŸ˜‚ðŸ˜‚  \n",
      "25                                                 ðŸ¤£ðŸ¤£  \n",
      "26  You're all welcome to the studio for a few min...  \n",
      "27     please take videos tuchoche nayo watu hii mtaa  \n",
      "28                                      image omitted  \n",
      "29                                      image omitted  \n",
      "30                                      video omitted  \n",
      "31                                      video omitted  \n",
      "32                       Facebook Consumers(Jan 2022)  \n",
      "33                                      image omitted  \n",
      "34           The Chinese embassy there has denied it.  \n",
      "35  Ooh, was the story on BBC or itâ€™s a fake scree...  \n",
      "36                                      It was on BBC  \n",
      "37                                        Interesting  \n",
      "38                                      image omitted  \n",
      "39                                      video omitted  \n",
      "40                                      image omitted  \n",
      "41  An anonymous app called Gas is taking high sch...  \n",
      "42  Can we record the YouTube viewership numbers f...  \n",
      "43                                             On it.  \n",
      "44                   *Numbers at Start - 12:00Noon.*   \n",
      "45  **Everyone wants to be TikTok, and TikTok want...  \n",
      "46                   *Numbers - 12:35pm.* (Ent. End)   \n",
      "47                  *Numbers - 12:46pm.* (DP Adress)   \n",
      "48         *Numbers - 12:50pm.* (Presidentâ€™s Adress)   \n",
      "49                                                 ðŸ‘ðŸ¾  \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"Remove invisible Unicode characters like the Left-to-Right Mark.\"\"\"\n",
    "    return re.sub(r'[\\u200e\\u200f]', '', text)\n",
    "\n",
    "def parse_user_message(line):\n",
    "    # Regular expression to capture date, time, author, and message for standard messages\n",
    "    regex_pattern = r\"^\\[(\\d{1,2}/\\d{1,2}/\\d{4}), (\\d{2}:\\d{2}:\\d{2})\\] ([^:]+): (.*)$\"\n",
    "    \n",
    "    match = re.match(regex_pattern, clean_text(line))\n",
    "    if match:\n",
    "        date = match.group(1)\n",
    "        time = match.group(2)\n",
    "        author = match.group(3)\n",
    "        message = match.group(4)\n",
    "    elif \"omitted\" in line:\n",
    "        parts = clean_text(line).split('] ', 1)\n",
    "        datetime_part = parts[0].strip('[')\n",
    "        rest = parts[1] if len(parts) > 1 else \"\"\n",
    "        author_message = rest.split(': ', 1)\n",
    "        author = author_message[0] if len(author_message) > 1 else \"Unknown\"\n",
    "        message = \"Media Omitted\"\n",
    "        date, time = datetime_part.split(', ')\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "    date_time_str = f\"{date}, {time}\"\n",
    "    # Using clean_text to ensure no invisible characters are present\n",
    "    date_time = datetime.strptime(clean_text(date_time_str), '%d/%m/%Y, %H:%M:%S')\n",
    "    return {'DateTime': date_time, 'Author': author, 'Message': message}\n",
    "\n",
    "# Assuming you are reading the chat file as before\n",
    "with open('data/_chat.txt', encoding='utf-8') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Parse lines and filter out None values\n",
    "parsed_data = filter(None, (parse_user_message(line) for line in lines))\n",
    "\n",
    "# Convert to a DataFrame\n",
    "df = pd.DataFrame(list(parsed_data))\n",
    "\n",
    "# Display the DataFrame or proceed with further analysis\n",
    "print(df.head(50))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Total Messages, Media, and Members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Imgae Media Messages: 1161\n"
     ]
    }
   ],
   "source": [
    "media_messages = df[df['Message'] == 'image omitted']\n",
    "print(f\"Total Imgae Media Messages: {len(media_messages)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Media Messages: 1650\n"
     ]
    }
   ],
   "source": [
    "# Define a list of patterns that WhatsApp uses for omitted media messages\n",
    "media_patterns = [\n",
    "    'image omitted',\n",
    "    'video omitted',\n",
    "    'GIF omitted',\n",
    "    'audio omitted',\n",
    "    'document omitted',\n",
    "    'sticker omitted'\n",
    "]\n",
    "\n",
    "# Combine the patterns into a single regex expression\n",
    "media_regex = '|'.join([f\"\\\\b{pattern}\\\\b\" for pattern in media_patterns])\n",
    "\n",
    "# Filter messages containing any of the media patterns and count them\n",
    "media_messages_count = df[df['Message'].str.contains(media_regex, case=False, na=False)].shape[0]\n",
    "\n",
    "print(f\"Total Media Messages: {media_messages_count}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Messages: 6038\n",
      "Total Members: 25\n"
     ]
    }
   ],
   "source": [
    "total_messages = len(df)\n",
    "total_members = df['Author'].nunique()\n",
    "\n",
    "print(f\"Total Messages: {total_messages}\")\n",
    "print(f\"Total Members: {total_members}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "notebook_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
